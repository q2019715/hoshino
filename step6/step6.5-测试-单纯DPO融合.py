import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import os

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================

# 1. åŸå§‹åŸºåº§ (ä½ åšå®éªŒæ—¶ç”¨çš„é‚£ä¸ª Instruct ç‰ˆ)
BASE_MODEL_ID = "Qwen/Qwen2.5-7B-Instruct"

# 2. DPO æƒé‡è·¯å¾„ (ä½ çš„å®éªŒè¾“å‡ºç›®å½•)
# âš ï¸ è¿™é‡Œå¡«å†™ä½ åˆšåˆšè·‘å®Œçš„é‚£ä¸ª "ç›´æ¥ DPO" çš„è¾“å‡ºç›®å½•
DPO_ADAPTER_PATH = "./hoshino_dpo_direct_fail_test"

# 3. æœ€ç»ˆè¾“å‡ºè·¯å¾„ (åˆå¹¶åçš„å®Œæ•´æ¨¡å‹)
OUTPUT_DIR = "./Hoshino-DirectDPO-Experiment-Full"


# ==============================================

def main():
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ [åŸºåº§ + DPO] ç›´æ¥ç†”ç‚¼ (è·³è¿‡ SFT)...")

    # 1. åŠ è½½ Tokenizer
    print(f"ğŸ“¥ åŠ è½½ Tokenizer: {BASE_MODEL_ID}")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)

    # 2. åŠ è½½åŸºåº§æ¨¡å‹
    # å¿…é¡»ç”¨ float16 æˆ– bfloat16ï¼Œä¸èƒ½ç”¨ 4bit/8bit é‡åŒ–åŠ è½½ï¼Œå¦åˆ™æ— æ³•è¿›è¡Œ merge
    print(f"ğŸ“¥ åŠ è½½åŸºåº§æ¨¡å‹: {BASE_MODEL_ID} (FP16 Mode)...")
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_ID,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
        low_cpu_mem_usage=True
    )

    # 3. ç›´æ¥åŠ è½½å¹¶åˆå¹¶ DPO æƒé‡
    print(f"ğŸ”¨ æ­£åœ¨å°† DPO LoRA ({DPO_ADAPTER_PATH}) ç†”ç‚¼è¿›åŸºåº§...")

    try:
        # ç›´æ¥æŠŠ DPO çš„ LoRA æŒ‚è½½åˆ°åŸºåº§ä¸Š
        model_to_merge = PeftModel.from_pretrained(base_model, DPO_ADAPTER_PATH)

        # æ‰§è¡Œåˆå¹¶ (Merge and Unload)
        final_model = model_to_merge.merge_and_unload()
        print("âœ… DPO æƒé‡èåˆå®Œæ¯•ï¼")

    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½ DPO æƒé‡ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€… adapter_config.json æ˜¯å¦å­˜åœ¨ã€‚")
        print(f"è¯¦ç»†æŠ¥é”™: {e}")
        return

    # 4. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å®Œæ•´æ¨¡å‹åˆ°: {OUTPUT_DIR} ...")

    # ä¿å­˜æƒé‡
    final_model.save_pretrained(OUTPUT_DIR)

    # ä¿å­˜ Tokenizer
    tokenizer.save_pretrained(OUTPUT_DIR)

    # ä¿å­˜ç”Ÿæˆé…ç½® (Generation Config) - é˜²æ­¢æ¨ç†æ—¶ç¼ºå°‘ eos_token å®šä¹‰
    try:
        base_model.generation_config.save_pretrained(OUTPUT_DIR)
        print("âœ… Generation Config å·²ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸ Generation Config ä¿å­˜å¤±è´¥ (éè‡´å‘½é”™è¯¯): {e}")

    print("\n" + "=" * 50)
    print(f"ğŸ‰ å®éªŒæ¨¡å‹å·²æ„å»ºå®Œæˆï¼š{OUTPUT_DIR}")
    print("ä½ å¯ä»¥ç›´æ¥ç”¨ vLLM æˆ– Ollama åŠ è½½è¿™ä¸ªæ–‡ä»¶å¤¹è¿›è¡Œæµ‹è¯•äº†ã€‚")
    print("=" * 50)


if __name__ == "__main__":
    main()